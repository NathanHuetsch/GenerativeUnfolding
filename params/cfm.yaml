run_name: long-erf_norm-nonBayesian-2500_epochs
run_folder: CFM

method: GenerativeUnfolding

process: ZJetsGenerative
process_params:
  train_slice: [0., 0.6]
  val_slice: [0.6, 0.65]
  test_slice: [0.65, 1.0]
  training_file: "data/Pythia26_full.npz"
  analysis_file: "data/Herwig_full.npz"

# Preprocessing
hard_preprocessing:
  # add uniform noise [-0.5, 0.5] to these channels
  uniform_noise_channels: []
  unit_hypercube: True
  erf_norm: True
reco_preprocessing:
  uniform_noise_channels: []
  unit_hypercube: True
  erf_norm: True

# Training
lr: 1.e-3
batch_size: 1024
batch_size_sample: 10000
lr_scheduler: cosine_annealing
weight_decay: 0.
betas: [0.9, 0.99]
epochs: 2500

# Architecture
model: CFM
bayesian: False
bayesian_samples: 20

latent_space: gaussian
#uniform_channels: [4]
#uniform_bounds: [0., 1.]
minimum_noise_scale: 0
t_noise_scale: 0

network_params:
  network_class: Subnet
  internal_size: 76
  layers_per_block: 4
  activation: SiLU

  embed_t: False
  embed_t_mode: gfprojection
  embed_t_dim: 16

  embed_c: False
  embed_c_dim: 32
  embed_c_params:
    internal_size: 64
    layers_per_block: 4
    activation: SiLU

  embed_x: False
  embed_x_dim: 32
  embed_x_params:
    internal_size: 64
    layers_per_block: 4
    activation: SiLU

solver: ODE
solver_params:
  t_min: 0
  t_max: 1
  mixed_precision: False
  sde_method: srk
  ode_method: dopri5
  atol: 1.e-5
  rtol: 1.e-5
  step_size: 1.e-2

evaluate_train: True
evaluate_analysis: True
evaluate_best: True