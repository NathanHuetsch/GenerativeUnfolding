run_name: 6_layers-64_wide-gaussian_latent-cosine_annealing-40_epochs
run_folder: CFM

method: GenerativeUnfolding
process_params:
  train_slice: [0., 0.6]
  val_slice: [0.6, 0.65]
  test_slice: [0.65, 1.0]
  training_file: "data/Pythia26_full.npz"
  analysis_file: "data/Herwig_full.npz"

# Preprocessing
hard_preprocessing:
  type:
  unit_hypercube: False
  args:
    pt_conserved: True
reco_preprocessing:
  type:

# Training
lr: 1.e-3
batch_size: 128
batch_size_sample: 10000
lr_scheduler: cosine_annealing
weight_decay: 0.
betas: [0.9, 0.99]
epochs: 40

# Architecture
model: CFM
latent_space: gaussian
uniform_channels: [5]
uniform_bounds: [0., 1.]
add_noise: False
add_noise_scale: 1.e-5

network_params:
  network_class: Subnet
  internal_size: 64
  layers_per_block: 6
  activation: SiLU

  embed_t: False
  embed_t_mode: gfprojection
  embed_t_dim: 16

  embed_c: False
  embed_c_dim: 32
  embed_c_params:
    internal_size: 64
    layers_per_block: 4
    activation: SiLU

  embed_x: False
  embed_x_dim: 32
  embed_x_params:
    internal_size: 64
    layers_per_block: 4
    activation: SiLU

ODE_params:
  t_min: 0
  t_max: 1
  mixed_precision: False
  method: dopri5
  atol: 1.e-5
  rtol: 1.e-5
  step_size: 1.e-2

evaluate_train: True
evaluate_analysis: True
evaluate_best: True